import discord
from discord.ext import commands
from langchain_huggingface import HuggingFaceEndpoint
import os
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
import fitz  # PyMuPDF
from langchain_huggingface import HuggingFaceEndpoint
from langchain_core.runnables import RunnableLambda
from langchain_google_genai import ChatGoogleGenerativeAI
from googleapiclient.discovery import build
import re
import asyncio

load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
openai_api_key = os.getenv("OPENAI_API_KEY")

HUGGINGFACE_API_TOKEN = os.getenv("HUGGINGFACE_API_TOKEN")
gemini_Token = os.getenv("gemini_token")
TARGET_CHANNEL_ID = 1380857846706471004
# âœ… ê¶Œì¥ ëª¨ë¸ (ì„±ëŠ¥ ì•ˆì •)
HF_MODEL_ID = "HuggingFaceH4/zephyr-7b-beta"

# ğŸ”— LangChain LLM ì´ˆê¸°í™”
llm = ChatOpenAI(
    temperature=0.3,  # ì°½ì˜ì„± (0.0 ~ 2.0)
    model_name="gpt-4.1-nano",  # ëª¨ë¸ëª…
)
llm2 = ChatGoogleGenerativeAI(
    model="models/gemini-2.0-flash", google_api_key=gemini_Token, temperature=0.7
)
# llm3 = ChatGoogleGenerativeAI(
#     model="models/gemini-1.5-pro", google_api_key=gemini_Token, temperature=0.7
# )
llm3 = ChatOpenAI(
    temperature=0.3,  # ì°½ì˜ì„± (0.0 ~ 2.0)
    model_name="gpt-4.1-mini",  # ëª¨ë¸ëª…
)
template1 = [
    (
        "system",
        "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ êµ­ë©˜ì…ë‹ˆë‹¤."
        "ì–´ë–¤ ì–¸ì–´ë¡œ ì§ˆë¬¸í•˜ë”ë¼ë„ í•­ìƒ í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.",
    ),
    ("human", "ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”:\n\n{query}"),
]


template2 = [
    (
        "system",
        "ë‹¹ì‹ ì€ ì¹œì ˆí•œ PDF ìš”ì•½ AI, 'êµ­ë©˜_pdf'ì…ë‹ˆë‹¤. "
        "í•­ìƒ í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê²Œ ìš”ì•½í•˜ë©°, ì˜ì–´ ì…ë ¥ ì‹œ 'ì…ë ¥í•˜ì‹  ì˜ì–´ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ ë“œë¦½ë‹ˆë‹¤.'ë¼ëŠ” ë¬¸ì¥ì„ ë¨¼ì € ë¶™ì´ì„¸ìš”. "
        "ê¸´ ë¬¸ì„œëŠ” ì„¹ì…˜ë³„ ìš”ì•½ ë° ì¸ì‚¬ì´íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”í•´ ì£¼ì„¸ìš”.",
    ),
    ("human", "ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ì •ë¦¬í•´ì„œ ìš”ì•½í•´ì¤˜:\n\n{input_text}"),
    (
        "ai",
        """ì•ˆë…•í•˜ì„¸ìš”, êµ­ë©˜_pdfì…ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  PDF ë‚´ìš©ì„ ë‹¤ìŒê³¼ ê°™ì´ ìš”ì•½í•´ ë“œë¦½ë‹ˆë‹¤:

**[ë¬¸ì„œ ê°œìš”]**
- ì œëª©: (ìˆë‹¤ë©´ í‘œì‹œ)
- ì €ì: (ìˆë‹¤ë©´ í‘œì‹œ)
- ì£¼ìš” ë‚´ìš©: (í•œ ì¤„ í•µì‹¬ ìš”ì•½)

**[ì£¼ìš” ì„¹ì…˜ ìš”ì•½]**
1. **ì„œë¡ **: â€¦
2. **ë³¸ë¡ **: â€¦
3. **ê²°ë¡ **: â€¦

**[í•µì‹¬ ì£¼ì¥ ë° ì¸ì‚¬ì´íŠ¸]**
- â€¦""",
    ),
]


template3 = [
    (
        "system",
        "ë‹¹ì‹ ì€ ì„¸ê³„ ìµœì´ˆì˜ ì™„ë²½í•œ í†µì—­ AIì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ë£Œ í†µì—­ê°€ì…ë‹ˆë‹¤.,ì–´ë–¤ ì–¸ì–´ë¥¼ ë¬¼ì–´ë³´ë©´ í•œêµ­ì–´ë¡œ í†µì—­ì„ í•´ì„¸ìš”",
    ),
    ("human", "ë‹¤ìŒ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ í†µì—­í•´ì¤˜:\n\n{language}"),
]

template4 = [
    (
        "system",
        "ë‹¹ì‹ ì€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì „ë¬¸ AIì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì´ë¦„ì€ 'í”„ë¡¬í”„íŠ¸_êµ­'ì…ë‹ˆë‹¤. "
        "ì‚¬ìš©ìê°€ íŠ¹ì • ì£¼ì œë¥¼ ì œê³µí•˜ë©´ í•´ë‹¹ ì£¼ì œì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”. "
        "ê° í”„ë¡¬í”„íŠ¸ëŠ” ì˜ë¬¸ê³¼ í•œê¸€ê³¼ ì¼ë³¸ì–´ë¡œ ê°ê° ì œê³µë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
    ),
    ("human", "ë‹¤ìŒ ì£¼ì œì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”:\n\n{prompt}"),
    (
        "ai",
        "**[English Prompt]**\nì§ˆë¬¸ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”.\n\n"
        "**[í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸]**\nì§ˆë¬¸ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”.\n\n"
        "**[ì¼ë³¸ì–´ í”„ë¡¬í”„íŠ¸]**\nì§ˆë¬¸ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¼ë³¸ì–´ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”.\n\n",
    ),
]

template5 = [
    (
        "system",
        "ë‹¹ì‹ ì€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê·¸ì— ë§ëŠ” ê°€ìˆ˜ ë…¸ë˜ë¥¼ 5ê°œ ì¶”ì²œí•˜ëŠ” ì¹œêµ¬ì…ë‹ˆë‹¤.\n"
        "ë…¸ë˜ë¥¼ ì¶”ì²œí•  ë•ŒëŠ” ë‹¤ìŒ í˜•ì‹ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:\n"
        "'ê°€ìˆ˜ - ë…¸ë˜ëª…'\n"
        "ì˜ˆì‹œ: 'ê¹€ë‚˜ì˜ - ì†”ì§í•˜ê²Œ ë§í•´ì„œ ë‚˜'\n"
        "ë¬´ì¡°ê±´ ì‘ì€ ë”°ì˜´í‘œ('') ì•ˆì— ê°€ìˆ˜ì™€ ì œëª©ì„ ë„£ì–´ì•¼ í•˜ë©°, ê·¸ ì™¸ì˜ ì„¤ëª…ì€ ììœ ë¡­ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.",
    ),
    ("human", "{sings}"),
]
# llm = HuggingFaceEndpoint(
#     repo_id=HF_MODEL_ID,
#     huggingfacehub_api_token=HUGGINGFACE_API_TOKEN,
#     temperature=0.7,
#     max_new_tokens=1024,
# )


def search_youtube(query, max_results=1):
    YOUTUBE_API_KEY = os.getenv("youtube_token")
    youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
    request = youtube.search().list(
        part="snippet", q=query, type="video", maxResults=max_results
    )
    response = request.execute()
    results = []
    for item in response["items"]:
        video_id = item["id"]["videoId"]
        url = f"https://www.youtube.com/watch?v={video_id}"
        results.append(url)

    return results


def extract_text_from_pdf(pdf_path):
    text = ""
    with fitz.open(pdf_path) as doc:
        for i, page in enumerate(doc):
            # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
            page_text = page.get_text().strip()
            text += page_text
    return text


# Discord ì„¤ì •
intents = discord.Intents.default()
intents.message_content = True
intents.members = True
bot = commands.Bot(command_prefix="/", intents=intents)


@bot.event
async def on_ready():
    print(f"âœ… ë´‡ ì ‘ì†: {bot.user.name}")


@bot.command(name="ì§ˆë¬¸")
async def question(ctx, *, query: str):
    if ctx.channel.id != TARGET_CHANNEL_ID:
        await ctx.send(f"âŒ ì´ ëª…ë ¹ì–´ëŠ” ì§€ì •ëœ ì±„ë„ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    prompt = ChatPromptTemplate.from_messages(template1)
    chain = prompt | llm | StrOutputParser()
    result = chain.invoke({"query": query})
    MAX_LENGTH = 1500
    for i in range(0, len(result), MAX_LENGTH):
        chunk = result[i : i + MAX_LENGTH]
        await ctx.channel.send(f"{ctx.author.mention}{chunk}")


@bot.command(name="ë²ˆì—­")
async def transfer(ctx, *, language: str):
    if ctx.channel.id != TARGET_CHANNEL_ID:
        await ctx.send(f"âŒ ì´ ëª…ë ¹ì–´ëŠ” ì§€ì •ëœ ì±„ë„ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    prompt = ChatPromptTemplate.from_messages(template3)
    chain = prompt | llm2 | StrOutputParser()
    result = chain.invoke({"language": language})
    MAX_LENGTH = 1500
    for i in range(0, len(result), MAX_LENGTH):
        chunk = result[i : i + MAX_LENGTH]
        await ctx.channel.send(f"{ctx.author.mention}{chunk}")


@bot.command(name="ë…¸ë˜ì¶”ì²œ")
async def sing(ctx, *, sings: str):
    prompt = ChatPromptTemplate.from_messages(template5)
    chain = prompt | llm | StrOutputParser()
    result = chain.invoke({"sings": sings})
    matches = re.findall(r"'(.+?)'", result)
    link_list = []
    for raw in matches:
        links = search_youtube(raw)
        links = links[0]
        link_list.append(links)
    print(link_list)
    MAX_LENGTH = 1500
    for i in range(0, len(result), MAX_LENGTH):
        chunk = result[i : i + MAX_LENGTH]
        await ctx.channel.send(f"{ctx.author.mention}{chunk}")
    for sing in link_list:
        await ctx.channel.send(f"m!play {sing}")
        await asyncio.sleep(2)


@bot.command(name="ìƒì„±")
async def prompt(ctx, *, prompts: str):
    if ctx.channel.id != TARGET_CHANNEL_ID:
        await ctx.send(f"âŒ ì´ ëª…ë ¹ì–´ëŠ” ì§€ì •ëœ ì±„ë„ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    prompt = ChatPromptTemplate.from_messages(template4)
    chain = prompt | llm3 | StrOutputParser()
    result = chain.invoke({"prompt": prompts})
    MAX_LENGTH = 1500
    for i in range(0, len(result), MAX_LENGTH):
        chunk = result[i : i + MAX_LENGTH]
        await ctx.channel.send(f"{ctx.author.mention}{chunk}")


@bot.command(name="ìš”ì•½")
async def summary_content(ctx, *, query: str = None):
    if ctx.channel.id != TARGET_CHANNEL_ID:
        await ctx.send(f"âŒ ì´ ëª…ë ¹ì–´ëŠ” ì§€ì •ëœ ì±„ë„ì—ì„œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    if query:
        prompt = ChatPromptTemplate.from_messages(template2)
        chain = prompt | llm2 | StrOutputParser()
        response = chain.invoke({"input_text": query})
        await ctx.channel.send(f"{ctx.author.mention} ğŸ“„ ìš”ì•½ ê²°ê³¼:\n{response}")
        return

        # ì²¨ë¶€ëœ PDF ìš”ì•½ ì²˜ë¦¬
    elif ctx.message.attachments:
        for file in ctx.message.attachments:
            if file.filename.endswith(".pdf"):
                file_path = f"./{file.filename}"
                await file.save(file_path)

                content = extract_text_from_pdf(file_path)

                prompt = ChatPromptTemplate.from_messages(template2)
                chain = prompt | llm2 | StrOutputParser()
                result = chain.invoke({"input_text": content})
                MAX_LENGTH = 1500
                for i in range(0, len(result), MAX_LENGTH):
                    chunk = result[i : i + MAX_LENGTH]

                    await ctx.channel.send(f"{ctx.author.mention}{chunk}")
                os.remove(file_path)


bot.run(DISCORD_TOKEN)
